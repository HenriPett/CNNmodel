{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cnnmodel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnWKlYNRf0Ni6daPcr3Zyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenriPett/CNNmodel/blob/main/Cnnmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay4MMcdeyLXD"
      },
      "source": [
        "\"\"\"\n",
        "Recomendo que voce execute todo o codigo com a GPU do Google Colab, para isso:\n",
        "Ambiente de execução -> Alterar o tipo de ambiente de execução -> Acelerador de\n",
        "Hardware -> GPU -> Salvar\n",
        "\n",
        "Devo apontar que é normal o codigo demorar para ser executado, os processos de aprendizado\n",
        "e download são lentos.\n",
        "\n",
        "A acuracia desse modelo ficou em 93%, então as vezes ele ira errar.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEIfHxR1aj6Y"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmvJDjM4a_xe",
        "outputId": "4cdd8a4d-c049-4139-c3db-b41850df4d2b"
      },
      "source": [
        "#Pegamos o dataset CIFAR10, ele tem 60.000 imagens e 10 categorias\n",
        "\n",
        "#dividimos os dados em: dados de treino/dados de classificaçao e dados de teste/dados de classificaçao\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EXiGgKMbyFt"
      },
      "source": [
        "#pegando os dados e transformando os pixels das imagens em numeros entre 0 e 1\n",
        "\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKuDucPut1ss"
      },
      "source": [
        "#Transformando os labels, que antes eram numeros, em palavras que as classificam.\n",
        "labels = ['Avião', 'Carro', 'Passaro', 'Gato', 'Veado', 'Cachorro', 'Sapo', 'Cavalo', 'Navio', 'Caminhão']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0wt69P1cHMO"
      },
      "source": [
        "#inicializando o modelo como CNN e adicionando camadas a ela\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHSU2v2MclsO",
        "outputId": "a8cc9d50-224f-4c08-a1a2-03c9679e3438"
      },
      "source": [
        "#NÃO É NECESSARIO \n",
        "\"\"\" \n",
        "O método summary() traz varias informaçoes do modelo, como os informaçoes\n",
        "de saida e parametros de cada camada. Tambem informa o total de parametros,\n",
        "parametros treinaveis e parametros não treinaveis. \n",
        "\"\"\"\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 56,320\n",
            "Trainable params: 56,320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68PQA872dl1K",
        "outputId": "78e03beb-c9c4-4af5-cf7d-9d3a6751938f"
      },
      "source": [
        "\"\"\"\n",
        "Como apresentado acima no summary(), a tendencia do numero de outputs é diminuir\n",
        "a cada camada. Na ultima camada é possivel ver q o output é um array de 3 dimensões\n",
        "(4, 4, 64), ou seja, 1024 saidas (4x4x64=1024). Como o nosso dataset só tem 10 categorias\n",
        "o output da CNN deve ser 10 e apenas uma camada. Para transformar 3 camadas em uma,\n",
        "usamos uma camada Flatten (Achatar), e para transformar 1024 outputs em 10 adicionamos\n",
        "mais duas camadas densas (Dense).\n",
        "\"\"\"\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "#No metodo summary(), vemos que agora na ultima camada esta somente uma camada, e 10 outputs.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 123,924\n",
            "Trainable params: 123,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CM668zAiAvQ",
        "outputId": "980ffc6f-0335-4b67-fde7-882eef19a120"
      },
      "source": [
        "#compilando o modelo e otimizando-o com o \"adam\", um otimizador generico, focando em acuracia (accuracy)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\"\"\"\n",
        "Agora dando fit no modelo, onde voce coloca de parametros os dados de treino/labels\n",
        "e os dados de validaçao. O numero de Epochs (Epócas) depende do numero de vezes que \n",
        "voce quer que o modelo repasse pelos dados, assim aumentando a acuracia a cada passada.\n",
        "Na teoria, o correto seria colocar varias epochs, porem nao funciona assim devido ao\n",
        "overfitting, ou, vicio do modelo, onde ele vai ter uma acuracia muito alta,porem\n",
        "somente para os dados treinados, não sendo verdade para futuros dados de input.\n",
        "\"\"\"\n",
        "history = model.fit(train_images, train_labels, epochs=30, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1882 - accuracy: 0.9332 - val_loss: 1.6974 - val_accuracy: 0.6893\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1643 - accuracy: 0.9423 - val_loss: 1.6809 - val_accuracy: 0.6828\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1658 - accuracy: 0.9415 - val_loss: 1.7376 - val_accuracy: 0.6930\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1480 - accuracy: 0.9480 - val_loss: 1.7758 - val_accuracy: 0.6816\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1557 - accuracy: 0.9457 - val_loss: 1.8524 - val_accuracy: 0.6914\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1435 - accuracy: 0.9499 - val_loss: 1.8679 - val_accuracy: 0.6884\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1553 - accuracy: 0.9448 - val_loss: 1.8847 - val_accuracy: 0.6974\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1346 - accuracy: 0.9524 - val_loss: 1.9032 - val_accuracy: 0.6824\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1305 - accuracy: 0.9542 - val_loss: 1.9666 - val_accuracy: 0.6799\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1377 - accuracy: 0.9511 - val_loss: 1.9030 - val_accuracy: 0.6901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "jnaJVHS3lVhE",
        "outputId": "84ed55c0-a81c-4c5d-fb70-cea7a79b0864"
      },
      "source": [
        "\"\"\"\n",
        "Como a variavel test_images possui 10000 imagens dentro dela, usamos o metodo randint(),\n",
        "da biblioteca Random, para pegar um numero qualquer entre 0 e 9999. Com esse metodo,\n",
        "conseguimos pegar uma imagem aleatoria, e joga-la dentro do modelo, para assim, ocorrer a\n",
        "classificação da imagem.\n",
        "\"\"\"\n",
        "image_index = randint(0, 9999)\n",
        "plt.imshow(test_images[image_index])\n",
        "plt.show()\n",
        "\n",
        "pred = model.predict(test_images[image_index].reshape(1, 32, 32, 3))\n",
        "print(f'A imagem representa um: {labels[pred.argmax()]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "A imagem representa um: Caminhão\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}